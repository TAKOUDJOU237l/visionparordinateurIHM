import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/services.dart';
import 'package:path_provider/path_provider.dart';
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:image/image.dart' as img;

import '../../features/person_detection/data/models/bounding_box_model.dart';

/// Service r√©el pour la d√©tection de personnes avec MobileNet SSD
/// Utilise un mod√®le local inclus dans l'app (pas de t√©l√©chargement)
class TFLiteService {
  Interpreter? _interpreter;
  bool _isInitialized = false;
  String _currentModel = 'mobilenet';
  bool _useGpu = true; // Tente d'utiliser le GPU par d√©faut

  /// Initialise le service avec le mod√®le local
  Future<void> initialize({String model = 'mobilenet', bool? useGpu}) async {
    // Si useGpu est sp√©cifi√©, on met √† jour le flag
    if (useGpu != null) {
      _useGpu = useGpu;
    }

    if (_isInitialized && _currentModel == model) return;

    try {
      print(' Initialisation du service de d√©tection...');

      _currentModel = model;

      // Copier le mod√®le depuis les assets vers un fichier temporaire
      final modelPath = await _loadModelFromAssets();

      print('Chargement du mod√®le depuis: $modelPath');

      // Options pour l'interpr√©teur
      final options = InterpreterOptions()..threads = 4;

      // Ajouter le d√©l√©gu√© GPU si demand√© et disponible
      if (Platform.isAndroid && _useGpu) {
        try {
          options.addDelegate(GpuDelegateV2());
          print('‚úì GPU delegate activ√©');
        } catch (e) {
          print('‚ö† GPU non disponible, utilisation du CPU');
          _useGpu = false;
        }
      } else {
        print('‚ÑπÔ∏è Mode CPU activ√©');
      }

      // Charger le mod√®le
      _interpreter = Interpreter.fromFile(
        File(modelPath),
        options: options,
      );

      _isInitialized = true;
      print(' Mod√®le MobileNet SSD charg√© avec succ√®s!');

      // Afficher les informations du mod√®le
      _printModelInfo();

    } catch (e) {
      print(' Erreur lors de l\'initialisation: $e');
      _isInitialized = false;
      rethrow;
    }
  }

  /// Charge le mod√®le depuis les assets
  Future<String> _loadModelFromAssets() async {
    try {
      // Charger le mod√®le depuis assets/models/detect.tflite
      final modelData = await rootBundle.load('assets/models/detect.tflite');
      
      // Cr√©er un fichier temporaire
      final appDir = await getApplicationDocumentsDirectory();
      final modelFile = File('${appDir.path}/detect.tflite');
      
      // √âcrire les donn√©es dans le fichier
      await modelFile.writeAsBytes(
        modelData.buffer.asUint8List(
          modelData.offsetInBytes,
          modelData.lengthInBytes,
        ),
      );
      
      print('‚úì Mod√®le copi√© depuis les assets (${(modelData.lengthInBytes / 1024 / 1024).toStringAsFixed(2)} MB)');
      
      return modelFile.path;
    } catch (e) {
      print(' Erreur lors du chargement du mod√®le: $e');
      rethrow;
    }
  }

  /// Affiche les informations du mod√®le
  void _printModelInfo() {
    if (_interpreter == null) return;
    
    print(' Informations du mod√®le:');
    try {
      final inputTensors = _interpreter!.getInputTensors();
      final outputTensors = _interpreter!.getOutputTensors();
      
      print('   Inputs:');
      for (var tensor in inputTensors) {
        print('     - Shape: ${tensor.shape}, Type: ${tensor.type}');
      }
      
      print('   Outputs:');
      for (var tensor in outputTensors) {
        print('     - Shape: ${tensor.shape}, Type: ${tensor.type}');
      }
    } catch (e) {
      print('   Impossible d\'obtenir les infos du mod√®le: $e');
    }
  }

  /// D√©tecte les personnes dans une image
  Future<List<BoundingBoxModel>> detectPersons({
    required String imagePath,
    required double minConfidence,
  }) async {
    if (!_isInitialized) {
      await initialize();
    }

    try {
      print('üîç D√©tection en cours sur: $imagePath');
      
      // Charger et pr√©traiter l'image
      final imageBytes = await File(imagePath).readAsBytes();
      final image = img.decodeImage(imageBytes);
      
      if (image == null) {
        print('Impossible de d√©coder l\'image');
        return [];
      }
      
      print('üì∏ Image: ${image.width}x${image.height}');
      
      // D√©tection avec MobileNet SSD
      final detections = await _detectWithMobileNet(image, minConfidence);
      
      print(' ${detections.length} personne(s) d√©tect√©e(s)');
      
      return detections;
      
    } catch (e) {
      print(' Erreur lors de la d√©tection: $e');
      rethrow;
    }
  }

  /// D√©tection avec MobileNet SSD
  Future<List<BoundingBoxModel>> _detectWithMobileNet(
    img.Image image,
    double minConfidence,
  ) async {
    // Redimensionner l'image √† 300x300 (input de MobileNet SSD)
    final resized = img.copyResize(image, width: 300, height: 300);

    // Convertir en tenseur uint8 [1, 300, 300, 3]
    final inputBytes = _imageToByteListUint8(resized, 300);

    // Pr√©parer les outputs
    // MobileNet SSD quantized a 4 outputs:
    // Output 0: Locations [1, 10, 4] - coordonn√©es des bounding boxes
    // Output 1: Classes [1, 10] - identifiants des classes
    // Output 2: Scores [1, 10] - scores de confiance
    // Output 3: Number of detections [1] - nombre de d√©tections
    final outputLocations = List.generate(
      1,
      (_) => List.generate(10, (_) => List.filled(4, 0.0)),
    );
    final outputClasses = List.generate(1, (_) => List.filled(10, 0.0));
    final outputScores = List.generate(1, (_) => List.filled(10, 0.0));
    final numDetections = List.filled(1, 0.0);

    final outputs = {
      0: outputLocations,
      1: outputClasses,
      2: outputScores,
      3: numDetections,
    };

    // Ex√©cuter l'inf√©rence avec fallback CPU si GPU √©choue
    try {
      _interpreter!.runForMultipleInputs([inputBytes], outputs);
    } catch (e) {
      // Si le GPU delegate √©choue, on r√©initialise en mode CPU
      if (_useGpu) {
        print('‚ö†Ô∏è GPU delegate a √©chou√©, basculement vers CPU...');
        print('   Erreur: $e');

        // Fermer l'interpr√©teur actuel
        _interpreter?.close();
        _interpreter = null;
        _isInitialized = false;

        // R√©initialiser en mode CPU
        _useGpu = false;
        await initialize(model: _currentModel, useGpu: false);

        // R√©essayer l'inf√©rence en mode CPU
        print('üîÑ R√©essai de l\'inf√©rence en mode CPU...');
        _interpreter!.runForMultipleInputs([inputBytes], outputs);
      } else {
        // D√©j√† en mode CPU, propager l'erreur
        rethrow;
      }
    }

    // Extraire les d√©tections de personnes
    final detections = <BoundingBoxModel>[];
    final numDet = numDetections[0].toInt().clamp(0, 10);

    print('   Nombre de d√©tections brutes: $numDet');

    for (int i = 0; i < numDet; i++) {
      final score = outputScores[0][i];
      final classId = outputClasses[0][i].toInt();

      print('   D√©tection $i: classe=$classId, score=${score.toStringAsFixed(2)}');

      // Classe 0 = personne dans COCO dataset
      if (classId == 0 && score >= minConfidence) {
        // Les coordonn√©es sont normalis√©es [0, 1] dans l'ordre [ymin, xmin, ymax, xmax]
        final y1 = outputLocations[0][i][0];
        final x1 = outputLocations[0][i][1];
        final y2 = outputLocations[0][i][2];
        final x2 = outputLocations[0][i][3];

        detections.add(BoundingBoxModel(
          x: x1.clamp(0.0, 1.0),
          y: y1.clamp(0.0, 1.0),
          width: (x2 - x1).clamp(0.0, 1.0),
          height: (y2 - y1).clamp(0.0, 1.0),
          confidence: score,
        ));

        print(
          '   ‚úì Personne d√©tect√©e avec confiance ${(score * 100).toStringAsFixed(1)}%',
        );
      }
    }

    return detections;
  }

  /// Convertit une image en liste de bytes uint8 pour MobileNet
  Uint8List _imageToByteListUint8(img.Image image, int size) {
    final bytes = Uint8List(1 * size * size * 3);
    int pixelIndex = 0;
    
    for (int y = 0; y < size; y++) {
      for (int x = 0; x < size; x++) {
        final pixel = image.getPixel(x, y);
        bytes[pixelIndex++] = pixel.r.toInt();
        bytes[pixelIndex++] = pixel.g.toInt();
        bytes[pixelIndex++] = pixel.b.toInt();
      }
    }
    
    return bytes;
  }

  /// Change le mod√®le utilis√©
  Future<void> switchModel(String model) async {
    if (_currentModel == model) return;
    
    dispose();
    await initialize(model: model);
  }

  /// Lib√®re les ressources
  void dispose() {
    _interpreter?.close();
    _interpreter = null;
    _isInitialized = false;
    print(' Ressources lib√©r√©es');
  }
  
  /// V√©rifie si le service est initialis√©
  bool get isInitialized => _isInitialized;
  
  /// Retourne le mod√®le actuellement utilis√©
  String get currentModel => _currentModel;
}